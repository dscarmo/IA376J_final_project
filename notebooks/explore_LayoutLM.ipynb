{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "9epPwg52ExeB",
    "outputId": "23d0a4d2-341e-439c-d266-8706ea3ca72e"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'4.0.1'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IwWb1Y0iDmmY",
    "outputId": "c973bff9-c643-43af-cef6-0b74575d5eb3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LayoutLMConfig {\n  \"_name_or_path\": \"microsoft/layoutlm-base-uncased\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_2d_position_embeddings\": 1024,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"layoutlm\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"type_vocab_size\": 2,\n  \"vocab_size\": 30522\n}\n\n{'input_ids': tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102],\n        [  101,  7592,  1010,  2026,  3899,  2003, 10140,   102]],\n       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('last_hidden_state', torch.Size([2, 8, 768])),\n",
       " ('pooler_output', torch.Size([2, 768]))]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from transformers import LayoutLMModel, LayoutLMConfig, LayoutLMTokenizer\n",
    "\n",
    "tokenizer = LayoutLMTokenizer.from_pretrained('microsoft/layoutlm-base-uncased')\n",
    "model = LayoutLMModel.from_pretrained('microsoft/layoutlm-base-uncased').eval().cuda()\n",
    "\n",
    "print(model.config)\n",
    "\n",
    "inputs2 = inputs = tokenizer.encode_plus(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "inputs = tokenizer.encode_plus(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "for k, v in inputs.items():\n",
    "    inputs[k] = torch.cat((v.cuda(), inputs2[k].cuda()), dim=0)\n",
    "print(inputs)\n",
    "arange_bbox = torch.arange(64).reshape(2, 8, 4).cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=inputs[\"input_ids\"],\n",
    "                    attention_mask=inputs[\"attention_mask\"],\n",
    "                    token_type_ids=inputs[\"token_type_ids\"],\n",
    "                    bbox=arange_bbox)\n",
    "\n",
    "[(key, value.shape) for key, value in outputs.items()]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LayoutLM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}